from sentence_transformers import SentenceTransformer
import chromadb

# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
print("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
model = SentenceTransformer('intfloat/multilingual-e5-large')

# 2. Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
print("ğŸ”„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
client = chromadb.PersistentClient(path="data/database/chroma_db")
collection = client.get_collection("islamic_books_e5")

# 3. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø«
query = "Ù…Ù† Ù‡Ùˆ Ø§Ù„Ø´Ø±ÙŠÙ Ø§Ù„Ù…Ø±ØªØ¶Ù‰ØŸ"
print(f"\nğŸ” Ø§Ù„Ø³Ø¤Ø§Ù„: {query}\n")

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„Ù€ vector
query_embedding = model.encode(f"query: {query}")

# Ø§Ù„Ø¨Ø­Ø«
results = collection.query(
    query_embeddings=[query_embedding.tolist()],
    n_results=5
)

# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
print("ğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:\n")
for i, (id, metadata, doc) in enumerate(zip(
    results['ids'][0], 
    results['metadatas'][0],
    results['documents'][0]
), 1):
    print(f"{i}. {metadata['type']}: {id}")
    print(f"   {doc[:200]}...")
    print()