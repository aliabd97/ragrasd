# âš™ï¸ Multi-Level RAG System - Configuration File

# =============================================================================
# ğŸ“š PROJECT INFO
# =============================================================================
project:
  name: "Multi-Level RAG System"
  version: "1.0.0"
  description: "Ù†Ø¸Ø§Ù… RAG Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¯ÙŠÙ†ÙŠ"

# =============================================================================
# ğŸ“‚ PATHS
# =============================================================================
paths:
  # Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
  root: "."
  data: "./data"
  build: "./build"
  
  # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
  processed_data: "./data/processed"
  documents: "./data/processed/documents.json"
  sections: "./data/processed/sections.json"
  paragraphs: "./data/processed/paragraphs.json"
  
  # Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
  database: "./data/database"
  chroma_db: "./data/database/chroma_db"
  
  # Ø§Ù„Ø³Ø¬Ù„Ø§Øª
  logs: "./logs"
  cache: "./cache"

# =============================================================================
# ğŸ¤– AI CHUNKING (STEP 2)
# =============================================================================
chunking:
  # Claude API settings
  model: "claude-sonnet-4-20250514"  # Ø£Ø­Ø¯Ø« Ù†Ù…ÙˆØ°Ø¬
  max_tokens: 16000  # Ø£Ù‚ØµÙ‰ Ø·ÙˆÙ„ Ù„Ù„Ø±Ø¯
  temperature: 0  # Ø¯Ù‚Ø© Ù‚ØµÙˆÙ‰ (Ø¨Ø¯ÙˆÙ† Ø¥Ø¨Ø¯Ø§Ø¹)
  api_key_env: "ANTHROPIC_API_KEY"  # Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ± ÙÙŠ .env

  # Prompts location
  prompts_dir: "./build/prompts"

  # Output settings
  save_intermediate: true  # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¤Ù‚ØªØ©
  validate_output: true  # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

# =============================================================================
# ğŸ”¢ EMBEDDINGS MODEL (STEP 3)
# =============================================================================
embeddings:
  # Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø£Ù‚ÙˆÙ‰ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ© - Microsoft E5)
  provider: "sentence_transformers"
  model: "intfloat/multilingual-e5-large"
  
  # Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª
  dimension: 1024  # Ø£ÙƒØ¨Ø± Ù…Ù† paraphrase (768)
  max_length: 512  # tokens
  normalize: true
  
  # Ø§Ù„Ø£Ø¯Ø§Ø¡
  batch_size: 32
  device: "cpu"  # Ø£Ùˆ "cuda" Ø¥Ø°Ø§ ÙƒØ§Ù† GPU Ù…ØªØ§Ø­
  show_progress: true
  
  # Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
  cache_folder: "./cache/embeddings"
