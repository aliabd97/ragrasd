"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ Step 5: Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Ù†Ø¸Ø§Ù… Retrieval-Augmented Generation ÙƒØ§Ù…Ù„ Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¯ÙŠÙ†ÙŠ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠ

Ø§Ù„Ù…Ù‡Ø§Ù…:
1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Query Analyzer
2. Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ChromaDB
3. ØªØµÙÙŠØ© ÙˆØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
4. ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø°ÙƒÙŠØ©

Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 1.0.0
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import sys
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass
from datetime import datetime
import json

# Ø¥Ø¶Ø§ÙØ© build Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø±
sys.path.insert(0, str(Path(__file__).parent))

from sentence_transformers import SentenceTransformer
import chromadb

from step4_query_analyzer import QueryAnalyzer, QueryAnalysis


@dataclass
class SearchResult:
    """Ù†ØªÙŠØ¬Ø© Ø¨Ø­Ø« ÙˆØ§Ø­Ø¯Ø©"""
    id: str
    type: str  # document, section, paragraph
    content: str
    metadata: Dict
    distance: float  # Ø§Ù„Ù…Ø³Ø§ÙØ© (Ø£Ù‚Ù„ = Ø£ÙØ¶Ù„)
    score: float  # Ø§Ù„Ù†Ù‚Ø§Ø· (Ø£Ø¹Ù„Ù‰ = Ø£ÙØ¶Ù„)
    rank: int  # Ø§Ù„ØªØ±ØªÙŠØ¨


@dataclass
class RAGResponse:
    """Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù†Ø¸Ø§Ù… RAG"""
    query: str
    query_analysis: QueryAnalysis
    results: List[SearchResult]
    total_results: int
    search_time: float
    timestamp: str


class RAGSystem:
    """Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„"""

    def __init__(
        self,
        db_path: str = "data/database/chroma_db",
        collection_name: str = "islamic_books_e5",
        model_name: str = "intfloat/multilingual-e5-large"
    ):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… RAG

        Args:
            db_path: Ù…Ø³Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            collection_name: Ø§Ø³Ù… Collection
            model_name: Ø§Ø³Ù… Ù†Ù…ÙˆØ°Ø¬ Embeddings
        """
        print("ğŸ”„ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… RAG...")

        # ØªÙ‡ÙŠØ¦Ø© Query Analyzer
        print("   ğŸ“Š ØªØ­Ù…ÙŠÙ„ Query Analyzer...")
        self.analyzer = QueryAnalyzer()

        # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Embeddings
        print(f"   ğŸ¤– ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Embeddings: {model_name}...")
        self.model = SentenceTransformer(model_name)

        # Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        print(f"   ğŸ’¾ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {db_path}...")
        self.client = chromadb.PersistentClient(path=db_path)
        self.collection = self.client.get_collection(collection_name)

        print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… RAG Ø¨Ù†Ø¬Ø§Ø­!\n")

    def search(
        self,
        query: str,
        n_results: Optional[int] = None,
        filter_by_type: Optional[str] = None,
        min_score: float = 0.0
    ) -> RAGResponse:
        """
        Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

        Args:
            query: Ø§Ù„Ø³Ø¤Ø§Ù„
            n_results: Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (None = Ø§Ø³ØªØ®Ø¯Ù… Query Analyzer)
            filter_by_type: ØªØµÙÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹ (document/section/paragraph)
            min_score: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ù†Ù‚Ø§Ø·

        Returns:
            RAGResponse: Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        """
        start_time = datetime.now()

        # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„
        print(f"ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„: {query}")
        analysis = self.analyzer.analyze(query)

        # 2. ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        if n_results is None:
            n_results = analysis.search_strategy['n_results']

        print(f"   ğŸ“Š Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„: {analysis.query_type}")
        print(f"   ğŸŒ Ø§Ù„Ù„ØºØ©: {analysis.language}")
        print(f"   ğŸ“ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙØµÙŠÙ„: {analysis.detail_level}")
        print(f"   ğŸ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©: {n_results}\n")

        # 3. ØªÙˆÙ„ÙŠØ¯ Embedding Ù„Ù„Ø³Ø¤Ø§Ù„
        print("ğŸ”¢ ØªÙˆÙ„ÙŠØ¯ embedding Ù„Ù„Ø³Ø¤Ø§Ù„...")
        query_text = f"query: {query}"  # Ø¨Ø§Ø¯Ø¦Ø© E5
        query_embedding = self.model.encode(query_text)

        # 4. Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        print("ğŸ’¾ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")

        # Ø¥Ù†Ø´Ø§Ø¡ where filter Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
        where_filter = None
        if filter_by_type:
            where_filter = {"type": filter_by_type}

        db_results = self.collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=n_results * 2,  # Ø¬Ù„Ø¨ Ø¶Ø¹Ù Ø§Ù„Ø¹Ø¯Ø¯ Ù„Ù„ØªØµÙÙŠØ©
            where=where_filter
        )

        # 5. Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print("ğŸ“Š Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬...")
        results = self._process_results(
            db_results,
            analysis,
            min_score,
            n_results
        )

        # 6. Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª
        search_time = (datetime.now() - start_time).total_seconds()

        print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(results)} Ù†ØªÙŠØ¬Ø© ÙÙŠ {search_time:.2f} Ø«Ø§Ù†ÙŠØ©\n")

        return RAGResponse(
            query=query,
            query_analysis=analysis,
            results=results,
            total_results=len(results),
            search_time=search_time,
            timestamp=datetime.now().isoformat()
        )

    def _process_results(
        self,
        db_results: Dict,
        analysis: QueryAnalysis,
        min_score: float,
        n_results: int
    ) -> List[SearchResult]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""

        results = []

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        for i, (id, metadata, content, distance) in enumerate(zip(
            db_results['ids'][0],
            db_results['metadatas'][0],
            db_results['documents'][0],
            db_results['distances'][0]
        )):
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¥Ù„Ù‰ Ù†Ù‚Ø§Ø· (1 - distance)
            # ChromaDB ÙŠØ³ØªØ®Ø¯Ù… L2 distanceØŒ Ø£Ù‚Ù„ = Ø£ÙØ¶Ù„
            score = max(0, 1 - distance)

            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ù†Ù‚Ø§Ø·
            if score < min_score:
                continue

            # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª
            level_priority = analysis.search_strategy['level_priority']
            doc_type = metadata.get('type', 'unknown')

            # Ø¥Ø¶Ø§ÙØ© Ø¨ÙˆÙ†Øµ Ù„Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…ÙØ¶Ù„
            priority_bonus = 0
            if doc_type in level_priority:
                # Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ø£ÙˆÙ„Ù‰ ØªØ­ØµÙ„ Ø¹Ù„Ù‰ 0.1ØŒ Ø§Ù„Ø«Ø§Ù†ÙŠØ© 0.05ØŒ Ø¥Ù„Ø®
                position = level_priority.index(doc_type)
                priority_bonus = 0.1 / (position + 1)

            final_score = score + priority_bonus

            results.append(SearchResult(
                id=id,
                type=doc_type,
                content=content,
                metadata=metadata,
                distance=distance,
                score=final_score,
                rank=i + 1
            ))

        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        results.sort(key=lambda x: x.score, reverse=True)

        # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ±ØªÙŠØ¨
        for i, result in enumerate(results, 1):
            result.rank = i

        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ÙÙ‚Ø·
        return results[:n_results]

    def print_response(self, response: RAGResponse, verbose: bool = True):
        """Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø³Ù‚"""

        print("\n" + "="*70)
        print("ğŸ“‹ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«")
        print("="*70)

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„
        if verbose:
            print(f"\nğŸ“ Ø§Ù„Ø³Ø¤Ø§Ù„: {response.query}")
            print(f"ğŸŒ Ø§Ù„Ù„ØºØ©: {response.query_analysis.language}")
            print(f"ğŸ“Š Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„: {response.query_analysis.query_type}")
            print(f"ğŸ“ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙØµÙŠÙ„: {response.query_analysis.detail_level}")

        # Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        if verbose and response.query_analysis.keywords:
            print(f"\nğŸ”‘ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {', '.join(response.query_analysis.keywords[:5])}")

        # Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print(f"\nğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {response.total_results}")
        print(f"â±ï¸  Ø§Ù„ÙˆÙ‚Øª: {response.search_time:.2f} Ø«Ø§Ù†ÙŠØ©")

        print("\n" + "-"*70)
        print("ğŸ¯ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        print("-"*70)

        for i, result in enumerate(response.results, 1):
            print(f"\n{i}. [{result.type.upper()}] {result.id}")
            print(f"   ğŸ“Š Ø§Ù„Ù†Ù‚Ø§Ø·: {result.score:.4f} | Ø§Ù„Ù…Ø³Ø§ÙØ©: {result.distance:.4f}")

            # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø¥Ø°Ø§ ÙˆØ¬Ø¯
            if 'title' in result.metadata:
                print(f"   ğŸ“– Ø§Ù„ÙƒØªØ§Ø¨: {result.metadata['title']}")

            if 'author' in result.metadata:
                print(f"   âœï¸  Ø§Ù„Ù…Ø¤Ù„Ù: {result.metadata['author']}")

            # Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            content_preview = result.content[:200] + "..." if len(result.content) > 200 else result.content
            print(f"   ğŸ“ {content_preview}")

            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
            if verbose:
                if 'word_count' in result.metadata:
                    print(f"   ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {result.metadata['word_count']}")

        print("\n" + "="*70 + "\n")

    def ask(self, query: str, **kwargs) -> RAGResponse:
        """
        ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ù„Ø³Ø¤Ø§Ù„

        Args:
            query: Ø§Ù„Ø³Ø¤Ø§Ù„
            **kwargs: Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø¨Ø­Ø«

        Returns:
            RAGResponse
        """
        response = self.search(query, **kwargs)
        self.print_response(response)
        return response


def main():
    """ØªØ¬Ø±Ø¨Ø© Ù†Ø¸Ø§Ù… RAG"""

    print("\n" + "="*70)
    print("ğŸš€ Step 5: Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„")
    print("="*70 + "\n")

    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
    rag = RAGSystem()

    # Ø£Ù…Ø«Ù„Ø© Ù…ØªÙ†ÙˆØ¹Ø©
    test_queries = [
        "Ù…Ù† Ù‡Ùˆ Ø§Ù„Ø´Ø±ÙŠÙ Ø§Ù„Ù…Ø±ØªØ¶Ù‰ØŸ",
        "Ù…Ø§ Ù‡Ùˆ ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø¥Ù…Ø§Ù…Ø© ÙÙŠ Ø§Ù„ÙÙƒØ± Ø§Ù„Ø´ÙŠØ¹ÙŠØŸ",
        "Ø§Ø´Ø±Ø­ Ø¨Ø§Ù„ØªÙØµÙŠÙ„ Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ø¹ØµÙ…Ø©",
        "Ù…Ø§ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø¥Ù…Ø§Ù…Ø© ÙˆØ§Ù„Ø®Ù„Ø§ÙØ©ØŸ",
    ]

    for i, query in enumerate(test_queries, 1):
        print(f"\n{'â”'*70}")
        print(f"Ø³Ø¤Ø§Ù„ {i}/{len(test_queries)}")
        print(f"{'â”'*70}\n")

        response = rag.ask(query)

        # ÙØ§ØµÙ„ Ø¨ÙŠÙ† Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
        if i < len(test_queries):
            input("\nØ§Ø¶ØºØ· Enter Ù„Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ...")

    print("\n" + "="*70)
    print("âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±!")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
