"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ Step 5 AI: Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Ù†Ø¸Ø§Ù… RAG Ø°ÙƒÙŠ ÙŠØ³ØªØ®Ø¯Ù… AI Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªÙ‚Ø¯Ù…

Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©:
1. ØªØ­Ù„ÙŠÙ„ Ø°ÙƒÙŠ Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM
2. Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø¨Ø­Ø« Ù…Ø®ØµØµØ© Ù…Ù† AI
3. ÙÙ„ØªØ±Ø© ÙˆØªØ±ØªÙŠØ¨ Ø°ÙƒÙŠ Ù„Ù„Ù†ØªØ§Ø¦Ø¬
4. ØªÙØ³ÙŠØ± AI Ù„Ù„Ø³Ø¤Ø§Ù„

Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 2.0.0 (AI-Powered)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import sys
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass
from datetime import datetime

# Ø¥Ø¶Ø§ÙØ© build Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø±
sys.path.insert(0, str(Path(__file__).parent))

from sentence_transformers import SentenceTransformer
import chromadb

from step4_ai_query_analyzer import AIQueryAnalyzer, AIQueryAnalysis


@dataclass
class SearchResult:
    """Ù†ØªÙŠØ¬Ø© Ø¨Ø­Ø« ÙˆØ§Ø­Ø¯Ø©"""
    id: str
    type: str
    content: str
    metadata: Dict
    distance: float
    score: float
    rank: int
    relevance_explanation: str = ""  # Ø¬Ø¯ÙŠØ¯: ØªÙØ³ÙŠØ± Ø§Ù„ØµÙ„Ø© Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„


@dataclass
class AIRAGResponse:
    """Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ù€ AI"""
    query: str
    ai_analysis: AIQueryAnalysis  # ØªØ­Ù„ÙŠÙ„ AI ÙƒØ§Ù…Ù„
    results: List[SearchResult]
    total_results: int
    search_time: float
    timestamp: str


class AIRAGSystem:
    """Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""

    def __init__(
        self,
        db_path: str = "data/database/chroma_db",
        collection_name: str = "islamic_books_e5",
        model_name: str = "intfloat/multilingual-e5-large",
        llm_provider: str = "auto",
        llm_model: Optional[str] = None,
        use_ai_analyzer: bool = True
    ):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ø°ÙƒÙŠ

        Args:
            db_path: Ù…Ø³Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            collection_name: Ø§Ø³Ù… Collection
            model_name: Ø§Ø³Ù… Ù†Ù…ÙˆØ°Ø¬ Embeddings
            llm_provider: Ù…Ø²ÙˆØ¯ LLM (auto/openai/gemini/claude)
            llm_model: Ù†Ù…ÙˆØ°Ø¬ LLM Ù…Ø­Ø¯Ø¯
            use_ai_analyzer: Ø§Ø³ØªØ®Ø¯Ø§Ù… AI Analyzer Ø£Ù… Ù„Ø§
        """
        print("ğŸ”„ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ø°ÙƒÙŠ...")

        # ØªÙ‡ÙŠØ¦Ø© Query Analyzer
        print(f"   ğŸ“Š ØªØ­Ù…ÙŠÙ„ Query Analyzer (AI: {use_ai_analyzer})...")
        if use_ai_analyzer:
            self.analyzer = AIQueryAnalyzer(
                provider=llm_provider,
                model=llm_model,
                fallback_to_rules=True
            )
        else:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯
            from step4_query_analyzer import QueryAnalyzer
            self.analyzer = QueryAnalyzer()

        self.use_ai_analyzer = use_ai_analyzer

        # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Embeddings
        print(f"   ğŸ¤– ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Embeddings: {model_name}...")
        self.model = SentenceTransformer(model_name)

        # Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        print(f"   ğŸ’¾ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {db_path}...")
        self.client = chromadb.PersistentClient(path=db_path)
        self.collection = self.client.get_collection(collection_name)

        print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ø°ÙƒÙŠ Ø¨Ù†Ø¬Ø§Ø­!\n")

    def search(
        self,
        query: str,
        n_results: Optional[int] = None,
        filter_by_type: Optional[str] = None,
        min_score: float = 0.0,
        use_ai_filters: bool = True
    ) -> AIRAGResponse:
        """
        Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ù€ AI

        Args:
            query: Ø§Ù„Ø³Ø¤Ø§Ù„
            n_results: Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (None = Ø§Ø³ØªØ®Ø¯Ù… ØªÙˆØµÙŠØ© AI)
            filter_by_type: ØªØµÙÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
            min_score: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ù†Ù‚Ø§Ø·
            use_ai_filters: Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙ„Ø§ØªØ± AI Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©

        Returns:
            AIRAGResponse
        """
        start_time = datetime.now()

        # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ù€ AI
        print(f"ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„: {query}")

        if self.use_ai_analyzer:
            analysis = self.analyzer.analyze(query)
        else:
            # Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
            old_analysis = self.analyzer.analyze(query)
            # ØªØ­ÙˆÙŠÙ„ Ù„Ù„ØµÙŠØºØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
            analysis = self._convert_old_analysis(old_analysis, query)

        # 2. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¨Ø­Ø« Ù…Ù† AI
        if n_results is None:
            n_results = analysis.search_strategy.get('n_results', 5)

        print(f"\nğŸ’¡ ØªÙØ³ÙŠØ± AI:")
        print(f"   {analysis.ai_interpretation}")

        print(f"\nğŸ“Š Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¨Ø­Ø«:")
        print(f"   â€¢ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„: {analysis.query_type}")
        print(f"   â€¢ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙØµÙŠÙ„: {analysis.detail_level}")
        print(f"   â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {n_results}")
        print(f"   â€¢ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: {analysis.main_topic}")

        # 3. ØªÙˆÙ„ÙŠØ¯ Embedding Ù„Ù„Ø³Ø¤Ø§Ù„
        print(f"\nğŸ”¢ ØªÙˆÙ„ÙŠØ¯ embedding Ù„Ù„Ø³Ø¤Ø§Ù„...")
        query_text = f"query: {query}"
        query_embedding = self.model.encode(query_text)

        # 4. ØªØ·Ø¨ÙŠÙ‚ ÙÙ„Ø§ØªØ± AI Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©
        where_filter = None
        if use_ai_filters and filter_by_type is None:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙ„Ø§ØªØ± Ù…Ù† AI Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªØ§Ø­Ø©
            suggested_filters = analysis.search_strategy.get('suggested_filters', [])
            if suggested_filters:
                # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ø£ÙˆÙ„ (ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ† Ù‡Ø°Ø§)
                print(f"   ğŸ¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙ„ØªØ± AI: {suggested_filters[0]}")

        if filter_by_type:
            where_filter = {"type": filter_by_type}

        # 5. Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        print("ğŸ’¾ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")

        db_results = self.collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=n_results * 2,
            where=where_filter
        )

        # 6. Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø°ÙƒØ§Ø¡
        print("ğŸ“Š Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø°ÙƒØ§Ø¡...")
        results = self._process_results_with_ai(
            db_results,
            analysis,
            min_score,
            n_results
        )

        # 7. Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª
        search_time = (datetime.now() - start_time).total_seconds()

        print(f"\nâœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(results)} Ù†ØªÙŠØ¬Ø© ÙÙŠ {search_time:.2f} Ø«Ø§Ù†ÙŠØ©\n")

        return AIRAGResponse(
            query=query,
            ai_analysis=analysis,
            results=results,
            total_results=len(results),
            search_time=search_time,
            timestamp=datetime.now().isoformat()
        )

    def _process_results_with_ai(
        self,
        db_results: Dict,
        analysis: AIQueryAnalysis,
        min_score: float,
        n_results: int
    ) -> List[SearchResult]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª AI"""

        results = []

        # Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¨Ø­Ø« Ù…Ù† AI
        level_priority = analysis.search_strategy.get('level_priority', ['paragraph', 'section', 'document'])
        search_focus = analysis.search_strategy.get('search_focus', '')

        for i, (id, metadata, content, distance) in enumerate(zip(
            db_results['ids'][0],
            db_results['metadatas'][0],
            db_results['documents'][0],
            db_results['distances'][0]
        )):
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¥Ù„Ù‰ Ù†Ù‚Ø§Ø·
            base_score = max(0, 1 - distance)

            if base_score < min_score:
                continue

            # Ø¨ÙˆÙ†Øµ Ø­Ø³Ø¨ Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆÙ‰ (Ù…Ù† AI)
            doc_type = metadata.get('type', 'unknown')
            priority_bonus = 0
            if doc_type in level_priority:
                position = level_priority.index(doc_type)
                priority_bonus = 0.15 / (position + 1)  # Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„Ù‚Ø¯ÙŠÙ…

            # Ø¨ÙˆÙ†Øµ Ø¥Ø¶Ø§ÙÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
            topic_bonus = 0
            if analysis.main_topic:
                if analysis.main_topic.lower() in content.lower():
                    topic_bonus = 0.05

            # Ø¨ÙˆÙ†Øµ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            keyword_bonus = 0
            keywords_found = sum(1 for kw in analysis.keywords if kw.lower() in content.lower())
            if keywords_found > 0:
                keyword_bonus = min(0.1, keywords_found * 0.02)

            # Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            final_score = base_score + priority_bonus + topic_bonus + keyword_bonus

            # ØªÙØ³ÙŠØ± Ø§Ù„ØµÙ„Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            relevance_parts = []
            if topic_bonus > 0:
                relevance_parts.append(f"ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: {analysis.main_topic}")
            if keywords_found > 0:
                relevance_parts.append(f"ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ {keywords_found} ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ©")
            if priority_bonus > 0:
                relevance_parts.append(f"Ù…Ø³ØªÙˆÙ‰ Ù…Ù†Ø§Ø³Ø¨: {doc_type}")

            relevance_explanation = " | ".join(relevance_parts) if relevance_parts else "ØªØ´Ø§Ø¨Ù‡ Ø¯Ù„Ø§Ù„ÙŠ"

            results.append(SearchResult(
                id=id,
                type=doc_type,
                content=content,
                metadata=metadata,
                distance=distance,
                score=final_score,
                rank=i + 1,
                relevance_explanation=relevance_explanation
            ))

        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        results.sort(key=lambda x: x.score, reverse=True)

        # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ±ØªÙŠØ¨
        for i, result in enumerate(results, 1):
            result.rank = i

        return results[:n_results]

    def _convert_old_analysis(self, old_analysis, query: str) -> AIQueryAnalysis:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø¯ÙŠÙ… Ù„Ù„ØµÙŠØºØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"""
        # Ù‡Ø°Ø§ fallback Ù„Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        return AIQueryAnalysis(
            original_query=query,
            language=old_analysis.language,
            query_type=old_analysis.query_type,
            keywords=old_analysis.keywords,
            main_topic=old_analysis.keywords[0] if old_analysis.keywords else "unknown",
            sub_topics=old_analysis.keywords[1:3] if len(old_analysis.keywords) > 1 else [],
            detail_level=old_analysis.detail_level,
            complexity="moderate",
            search_strategy=old_analysis.search_strategy,
            ai_interpretation="ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ (Ø¨Ø¯ÙˆÙ† AI)",
            confidence=old_analysis.query_type_confidence,
            model_used="rules-based",
            metadata=old_analysis.metadata,
            timestamp=old_analysis.timestamp
        )

    def print_response(self, response: AIRAGResponse, verbose: bool = True):
        """Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø³Ù‚"""

        print("\n" + "="*70)
        print("ğŸ¤– Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ")
        print("="*70)

        # ØªØ­Ù„ÙŠÙ„ AI
        if verbose:
            print(f"\nğŸ“ Ø§Ù„Ø³Ø¤Ø§Ù„: {response.query}")
            print(f"ğŸ¤– Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {response.ai_analysis.model_used}")
            print(f"ğŸ“Š Ø§Ù„Ø«Ù‚Ø©: {response.ai_analysis.confidence:.0%}")
            print(f"\nğŸ’¡ ØªÙØ³ÙŠØ± AI:")
            print(f"   {response.ai_analysis.ai_interpretation}")

        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„
        print(f"\nğŸŒ Ø§Ù„Ù„ØºØ©: {response.ai_analysis.language}")
        print(f"ğŸ“‹ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„: {response.ai_analysis.query_type}")
        print(f"ğŸ¯ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: {response.ai_analysis.main_topic}")
        print(f"ğŸ“ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯: {response.ai_analysis.complexity}")

        # Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print(f"\nğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {response.total_results}")
        print(f"â±ï¸  Ø§Ù„ÙˆÙ‚Øª: {response.search_time:.2f} Ø«Ø§Ù†ÙŠØ©")

        print("\n" + "-"*70)
        print("ğŸ¯ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        print("-"*70)

        for i, result in enumerate(response.results, 1):
            print(f"\n{i}. [{result.type.upper()}] {result.id}")
            print(f"   ğŸ“Š Ø§Ù„Ù†Ù‚Ø§Ø·: {result.score:.4f} | Ø§Ù„Ù…Ø³Ø§ÙØ©: {result.distance:.4f}")

            # Ø³Ø¨Ø¨ Ø§Ù„ØµÙ„Ø©
            if result.relevance_explanation:
                print(f"   ğŸ¯ Ø§Ù„ØµÙ„Ø©: {result.relevance_explanation}")

            # Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
            if 'title' in result.metadata:
                print(f"   ğŸ“– Ø§Ù„ÙƒØªØ§Ø¨: {result.metadata['title']}")

            # Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            content_preview = result.content[:200] + "..." if len(result.content) > 200 else result.content
            print(f"   ğŸ“ {content_preview}")

        print("\n" + "="*70 + "\n")

    def ask(self, query: str, **kwargs) -> AIRAGResponse:
        """ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ù„Ø³Ø¤Ø§Ù„"""
        response = self.search(query, **kwargs)
        self.print_response(response)
        return response


def main():
    """ØªØ¬Ø±Ø¨Ø© Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ø°ÙƒÙŠ"""

    print("\n" + "="*70)
    print("ğŸš€ Step 5 AI: Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
    print("="*70 + "\n")

    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
    rag = AIRAGSystem(
        llm_provider="auto",       # Ø§Ø®ØªÙŠØ§Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ù…Ø²ÙˆØ¯
        use_ai_analyzer=True       # Ø§Ø³ØªØ®Ø¯Ø§Ù… AI
    )

    # Ø£Ù…Ø«Ù„Ø©
    test_queries = [
        "Ù…Ù† Ù‡Ùˆ Ø§Ù„Ø´Ø±ÙŠÙ Ø§Ù„Ù…Ø±ØªØ¶Ù‰ØŸ",
        "Ù…Ø§ Ù‡Ùˆ ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø¥Ù…Ø§Ù…Ø© ÙÙŠ Ø§Ù„ÙÙƒØ± Ø§Ù„Ø´ÙŠØ¹ÙŠØŸ",
        "Ø§Ø´Ø±Ø­ Ø¨Ø§Ù„ØªÙØµÙŠÙ„ Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ø¹ØµÙ…Ø© ÙˆØ£Ø¯Ù„ØªÙ‡",
    ]

    for i, query in enumerate(test_queries, 1):
        print(f"\n{'â”'*70}")
        print(f"Ø³Ø¤Ø§Ù„ {i}/{len(test_queries)}")
        print(f"{'â”'*70}\n")

        response = rag.ask(query)

        if i < len(test_queries):
            input("\nØ§Ø¶ØºØ· Enter Ù„Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ...")

    print("\n" + "="*70)
    print("âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±!")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
