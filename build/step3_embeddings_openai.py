#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Step 3: Generate Embeddings and Build Vector Database (OpenAI Version)
======================================================================

Ø§Ù„Ù…Ù‡Ù…Ø©:
- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Step 2
- ØªÙˆÙ„ÙŠØ¯ embeddings Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI (text-embedding-3-small/large)
- Ø¨Ù†Ø§Ø¡ ChromaDB vector database
- Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø«

Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: OpenAI text-embedding-3-small (Ø£Ùˆ large)
- Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: 1536 (small) Ø£Ùˆ 3072 (large)
- Ø§Ù„Ø¬ÙˆØ¯Ø©: Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹
- Ø§Ù„Ø³Ø±Ø¹Ø©: Ø³Ø±ÙŠØ¹
"""

import os
import json
import time
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime

import chromadb
from chromadb.config import Settings
from tqdm import tqdm
import yaml
from openai import OpenAI
from dotenv import load_dotenv


# ØªØ­Ù…ÙŠÙ„ environment variables
load_dotenv()


# =============================================================================
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# =============================================================================

def load_config(config_path: str = "../config.yaml") -> Dict:
    """ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


config = load_config()


# =============================================================================
# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù† config.yaml
# =============================================================================

# Paths
PROCESSED_DIR = Path(config['paths']['processed_data'])
DATABASE_DIR = Path(config['paths']['database'])
CHROMA_DB_PATH = Path(config['paths']['chroma_db'])

# OpenAI Settings
OPENAI_MODEL = config['embeddings']['openai']['model']
EMBEDDING_DIM = config['embeddings']['openai']['dimension']

# Files
DOCUMENTS_FILE = PROCESSED_DIR / "documents.json"
SECTIONS_FILE = PROCESSED_DIR / "sections.json"
PARAGRAPHS_FILE = PROCESSED_DIR / "paragraphs.json"
STATS_FILE = DATABASE_DIR / "embeddings_stats_openai.json"


# =============================================================================
# Class: OpenAIEmbeddingsGenerator
# =============================================================================

class OpenAIEmbeddingsGenerator:
    """
    Ù…ÙˆÙ„Ø¯ Embeddings Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI API
    """

    def __init__(self, model: str = OPENAI_MODEL):
        """
        Ø§Ù„ØªÙ‡ÙŠØ¦Ø©

        Args:
            model: Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (text-embedding-3-small Ø£Ùˆ text-embedding-3-large)
        """
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ API key
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("âŒ ÙŠØ±Ø¬Ù‰ ØªØ¹ÙŠÙŠÙ† OPENAI_API_KEY ÙÙŠ Ù…Ù„Ù .env")

        self.client = OpenAI(api_key=api_key)
        self.model = model

        print(f"ğŸ“¥ ØªÙ‡ÙŠØ¦Ø© OpenAI Embeddings: {model}")
        print(f"âœ… ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ OpenAI API")
        print()

    def encode_batch(
        self,
        texts: List[str],
        show_progress: bool = True
    ) -> List[List[float]]:
        """
        ØªØ­ÙˆÙŠÙ„ Ù†ØµÙˆØµ Ø¥Ù„Ù‰ embeddings

        Args:
            texts: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†ØµÙˆØµ
            show_progress: Ø¥Ø¸Ù‡Ø§Ø± progress bar

        Returns:
            Ù‚Ø§Ø¦Ù…Ø© embeddings
        """
        embeddings = []

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª (OpenAI ÙŠØ¯Ø¹Ù… Ø­ØªÙ‰ 2048 Ù†Øµ ÙÙŠ Ø·Ù„Ø¨ ÙˆØ§Ø­Ø¯)
        batch_size = 100  # Ù†Ø³ØªØ®Ø¯Ù… Ø¯ÙØ¹Ø§Øª Ø£ØµØºØ± Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¬Ø§ÙˆØ²

        iterator = range(0, len(texts), batch_size)
        if show_progress:
            iterator = tqdm(iterator, desc="ØªÙˆÙ„ÙŠØ¯ embeddings")

        for i in iterator:
            batch = texts[i:i + batch_size]

            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI API
            response = self.client.embeddings.create(
                input=batch,
                model=self.model
            )

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ embeddings
            batch_embeddings = [item.embedding for item in response.data]
            embeddings.extend(batch_embeddings)

            # ØªØ£Ø®ÙŠØ± ØµØºÙŠØ± Ù„ØªØ¬Ù†Ø¨ rate limiting
            time.sleep(0.1)

        return embeddings


# =============================================================================
# Class: ChromaDBBuilder
# =============================================================================

class ChromaDBBuilder:
    """Ø¨Ù†Ø§Ø¡ ChromaDB vector database"""

    def __init__(self, db_path: Path = CHROMA_DB_PATH):
        """
        Ø§Ù„ØªÙ‡ÙŠØ¦Ø©

        Args:
            db_path: Ù…Ø³Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        self.db_path = db_path

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯
        db_path.parent.mkdir(parents=True, exist_ok=True)

        # Ø¥Ù†Ø´Ø§Ø¡/ÙØªØ­ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        print(f"ğŸ“‚ ÙØªØ­ ChromaDB: {db_path}")
        self.client = chromadb.PersistentClient(
            path=str(db_path),
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )

        # Collection name
        self.collection_name = "islamic_books_openai"

        # Ø­Ø°Ù collection Ø§Ù„Ù‚Ø¯ÙŠÙ… Ø¥Ù† ÙˆØ¬Ø¯
        try:
            self.client.delete_collection(self.collection_name)
            print(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù collection Ø§Ù„Ù‚Ø¯ÙŠÙ…")
        except:
            pass

        # Ø¥Ù†Ø´Ø§Ø¡ collection Ø¬Ø¯ÙŠØ¯
        self.collection = self.client.create_collection(
            name=self.collection_name,
            metadata={
                "description": "Multi-level RAG for Islamic books using OpenAI",
                "model": OPENAI_MODEL,
                "dimension": EMBEDDING_DIM
            }
        )

        print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ collection: {self.collection_name}")

    def add_items(
        self,
        ids: List[str],
        embeddings: List[List[float]],
        documents: List[str],
        metadatas: List[Dict[str, Any]]
    ):
        """
        Ø¥Ø¶Ø§ÙØ© Ø¹Ù†Ø§ØµØ± Ø¥Ù„Ù‰ ChromaDB

        Args:
            ids: Ù…Ø¹Ø±ÙØ§Øª ÙØ±ÙŠØ¯Ø©
            embeddings: embeddings vectors
            documents: Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø£ØµÙ„ÙŠØ©
            metadatas: metadata Ù„ÙƒÙ„ Ø¹Ù†ØµØ±
        """
        self.collection.add(
            ids=ids,
            embeddings=embeddings,
            documents=documents,
            metadatas=metadatas
        )

    def get_stats(self) -> Dict:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        count = self.collection.count()

        # Ø¹Ø¯ ÙƒÙ„ Ù†ÙˆØ¹
        all_data = self.collection.get()
        docs_count = len([m for m in all_data['metadatas'] if m.get('type') == 'document'])
        secs_count = len([m for m in all_data['metadatas'] if m.get('type') == 'section'])
        paras_count = len([m for m in all_data['metadatas'] if m.get('type') == 'paragraph'])

        return {
            "total_items": count,
            "documents": docs_count,
            "sections": secs_count,
            "paragraphs": paras_count
        }


# =============================================================================
# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
# =============================================================================

def load_json(file_path: Path) -> List[Dict]:
    """ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù JSON"""
    print(f"ğŸ“‚ ØªØ­Ù…ÙŠÙ„: {file_path.name}")
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(data)} Ø¹Ù†ØµØ±")
    return data


def prepare_items(items: List[Dict], item_type: str) -> tuple:
    """
    ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¹Ù†Ø§ØµØ± Ù„Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ ChromaDB

    Args:
        items: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¹Ù†Ø§ØµØ±
        item_type: Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù†ØµØ± (document, section, paragraph)

    Returns:
        (ids, texts, metadatas)
    """
    ids = []
    texts = []
    metadatas = []

    for item in items:
        # ID
        if item_type == 'document':
            item_id = item['doc_id']
        elif item_type == 'section':
            item_id = item['section_id']
        else:  # paragraph
            item_id = item['para_id']

        ids.append(item_id)

        # Text - Ø§Ø³ØªØ®Ø¯Ø§Ù… summary Ù„Ù„Ù€ documents
        if item_type == 'document':
            texts.append(item.get('summary', item.get('text', '')))
        else:
            texts.append(item.get('text', ''))

        # Metadata
        metadata = {
            'type': item_type,
            'word_count': item.get('stats', {}).get('word_count', 0)
        }

        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        if item_type == 'document':
            metadata.update({
                'book': item.get('book', ''),
                'volume': item.get('volume', 0),
                'author': item.get('author', '')
            })
        elif item_type == 'section':
            metadata.update({
                'parent_doc': item.get('parent_doc', ''),
                'title': item.get('title', ''),
                'main_topic': item.get('main_topic', '')
            })
        else:  # paragraph
            metadata.update({
                'parent_section': item.get('parent_section', ''),
                'parent_doc': item.get('parent_doc', ''),
                'page': str(item.get('stats', {}).get('page', ''))
            })

        metadatas.append(metadata)

    return ids, texts, metadatas


# =============================================================================
# Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# =============================================================================

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""

    print("=" * 70)
    print("ğŸš€ Step 3: Embeddings with OpenAI")
    print("=" * 70)
    print(f"â„¹ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù…: {OPENAI_MODEL}")
    print(f"â„¹ï¸ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {EMBEDDING_DIM}")
    print()

    start_time = time.time()

    # =============================================================================
    # 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    # =============================================================================

    print("ğŸ“‚ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    print("-" * 70)

    documents = load_json(DOCUMENTS_FILE)
    sections = load_json(SECTIONS_FILE)
    paragraphs = load_json(PARAGRAPHS_FILE)

    total_items = len(documents) + len(sections) + len(paragraphs)
    print(f"\nğŸ“Š Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {total_items} Ø¹Ù†ØµØ±")
    print()

    # =============================================================================
    # 2. ØªÙ‡ÙŠØ¦Ø© Embeddings Generator
    # =============================================================================

    print("ğŸ“‚ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: ØªÙ‡ÙŠØ¦Ø© OpenAI Embeddings Generator")
    print("-" * 70)

    generator = OpenAIEmbeddingsGenerator()

    # =============================================================================
    # 3. ØªÙ‡ÙŠØ¦Ø© ChromaDB
    # =============================================================================

    print("ğŸ“‚ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: ØªÙ‡ÙŠØ¦Ø© ChromaDB")
    print("-" * 70)

    db = ChromaDBBuilder()
    print()

    # =============================================================================
    # 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Documents
    # =============================================================================

    print("ğŸ“‚ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ù…Ø¹Ø§Ù„Ø¬Ø© Documents")
    print("-" * 70)

    doc_ids, doc_texts, doc_metadatas = prepare_items(documents, 'document')

    print(f"ğŸ”¢ ØªÙˆÙ„ÙŠØ¯ OpenAI embeddings Ù„Ù€ {len(doc_texts)} document...")
    doc_embeddings = generator.encode_batch(doc_texts, show_progress=True)

    print(f"ğŸ’¾ Ø¥Ø¶Ø§ÙØ© Documents Ø¥Ù„Ù‰ ChromaDB...")
    db.add_items(doc_ids, doc_embeddings, doc_texts, doc_metadatas)
    print("âœ… ØªÙ…")
    print()

    # =============================================================================
    # 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Sections
    # =============================================================================

    print("ğŸ“‚ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5: Ù…Ø¹Ø§Ù„Ø¬Ø© Sections")
    print("-" * 70)

    sec_ids, sec_texts, sec_metadatas = prepare_items(sections, 'section')

    print(f"ğŸ”¢ ØªÙˆÙ„ÙŠØ¯ OpenAI embeddings Ù„Ù€ {len(sec_texts)} section...")
    sec_embeddings = generator.encode_batch(sec_texts, show_progress=True)

    print(f"ğŸ’¾ Ø¥Ø¶Ø§ÙØ© Sections Ø¥Ù„Ù‰ ChromaDB...")
    db.add_items(sec_ids, sec_embeddings, sec_texts, sec_metadatas)
    print("âœ… ØªÙ…")
    print()

    # =============================================================================
    # 6. Ù…Ø¹Ø§Ù„Ø¬Ø© Paragraphs
    # =============================================================================

    print("ğŸ“‚ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 6: Ù…Ø¹Ø§Ù„Ø¬Ø© Paragraphs")
    print("-" * 70)

    para_ids, para_texts, para_metadatas = prepare_items(paragraphs, 'paragraph')

    print(f"ğŸ”¢ ØªÙˆÙ„ÙŠØ¯ OpenAI embeddings Ù„Ù€ {len(para_texts)} paragraph...")
    para_embeddings = generator.encode_batch(para_texts, show_progress=True)

    print(f"ğŸ’¾ Ø¥Ø¶Ø§ÙØ© Paragraphs Ø¥Ù„Ù‰ ChromaDB...")
    db.add_items(para_ids, para_embeddings, para_texts, para_metadatas)
    print("âœ… ØªÙ…")
    print()

    # =============================================================================
    # 7. Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    # =============================================================================

    print("ğŸ“‚ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 7: Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©")
    print("-" * 70)

    db_stats = db.get_stats()

    total_time = time.time() - start_time

    stats = {
        "timestamp": datetime.now().isoformat(),
        "model": OPENAI_MODEL,
        "model_type": "OpenAI Embeddings",
        "embedding_dimension": EMBEDDING_DIM,

        "data": {
            "documents": len(documents),
            "sections": len(sections),
            "paragraphs": len(paragraphs),
            "total": total_items
        },

        "database": db_stats,

        "performance": {
            "total_time_seconds": round(total_time, 2),
            "total_time_minutes": round(total_time / 60, 2),
            "items_per_second": round(total_items / total_time, 2)
        },

        "model_info": {
            "advantages": [
                "Ø¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹",
                f"{EMBEDDING_DIM} Ø¨Ø¹Ø¯",
                "Ø¯Ø¹Ù… Ù…Ù…ØªØ§Ø² Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©",
                "Ø³Ø±ÙŠØ¹ ÙˆÙ…ÙˆØ«ÙˆÙ‚"
            ]
        }
    }

    # Ø­ÙØ¸ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    DATABASE_DIR.mkdir(parents=True, exist_ok=True)
    with open(STATS_FILE, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)

    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    print(f"ğŸ“Š Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:")
    print(f"   - Documents: {stats['data']['documents']}")
    print(f"   - Sections: {stats['data']['sections']}")
    print(f"   - Paragraphs: {stats['data']['paragraphs']}")
    print(f"   - Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {stats['data']['total']}")
    print()
    print(f"ğŸ’¾ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
    print(f"   - Ø§Ù„Ø¹Ù†Ø§ØµØ± ÙÙŠ ChromaDB: {db_stats['total_items']}")
    print(f"   - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {OPENAI_MODEL}")
    print(f"   - Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {EMBEDDING_DIM}")
    print(f"   - Ø§Ù„Ù…Ø³Ø§Ø±: {CHROMA_DB_PATH}")
    print()
    print(f"â±ï¸ Ø§Ù„Ø£Ø¯Ø§Ø¡:")
    print(f"   - Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {stats['performance']['total_time_minutes']:.2f} Ø¯Ù‚ÙŠÙ‚Ø©")
    print(f"   - Ø§Ù„Ø³Ø±Ø¹Ø©: {stats['performance']['items_per_second']:.2f} Ø¹Ù†ØµØ±/Ø«Ø§Ù†ÙŠØ©")
    print()
    print(f"ğŸ’¾ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ: {STATS_FILE}")
    print()

    # =============================================================================
    # 8. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø«
    # =============================================================================

    print("ğŸ“‚ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 8: Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø« (OpenAI)")
    print("-" * 70)

    # ØªØ¬Ø±Ø¨Ø© Ø¨Ø­Ø« Ø¨Ø³ÙŠØ·Ø©
    test_query = "Ø§Ù„Ø¥Ù…Ø§Ù…Ø©"
    print(f"ğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: '{test_query}'")

    query_embedding = generator.encode_batch([test_query], show_progress=False)[0]

    results = db.collection.query(
        query_embeddings=[query_embedding],
        n_results=3
    )

    print(f"\nğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Ø£ÙˆÙ„ 3):")
    for i, (doc_id, metadata) in enumerate(zip(results['ids'][0], results['metadatas'][0]), 1):
        print(f"\n{i}. ID: {doc_id}")
        print(f"   Ø§Ù„Ù†ÙˆØ¹: {metadata['type']}")
        if metadata['type'] == 'section':
            print(f"   Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {metadata.get('title', 'N/A')}")
        elif metadata['type'] == 'document':
            print(f"   Ø§Ù„ÙƒØªØ§Ø¨: {metadata.get('book', 'N/A')}")
        print(f"   Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {metadata['word_count']}")

    print()

    # =============================================================================
    # Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
    # =============================================================================

    print("=" * 70)
    print("âœ… ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Step 3 Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI!")
    print("=" * 70)
    print()
    print("ğŸ‰ Ø§Ù„Ø¢Ù† Ù„Ø¯ÙŠÙƒ embeddings Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø© Ù…Ù† OpenAI!")
    print(f"   - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {OPENAI_MODEL}")
    print(f"   - Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {EMBEDDING_DIM}")
    print(f"   - Ø§Ù„Ø¬ÙˆØ¯Ø©: Ù…Ù…ØªØ§Ø²Ø©")
    print()
    print("ğŸ“¦ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ø§ØªØ¬Ø©:")
    print(f"   - {CHROMA_DB_PATH}")
    print(f"   - {STATS_FILE}")
    print()
    print("ğŸ¯ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©: Step 5 - RAG System")
    print()


# =============================================================================
# Ø§Ù„ØªØ´ØºÙŠÙ„
# =============================================================================

if __name__ == "__main__":
    main()
