"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¤– Step 4 AI: Query Analyzer Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Ù…Ø­Ù„Ù„ Ø£Ø³Ø¦Ù„Ø© Ø°ÙƒÙŠ ÙŠØ³ØªØ®Ø¯Ù… LLMs (GPT-4, Gemini, Claude)

Ø§Ù„Ù…Ù‡Ø§Ù…:
1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI
2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚
3. ØªØ­Ø¯ÙŠØ¯ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø¨Ø­Ø« Ø°ÙƒÙŠØ©
4. Ø¯Ø¹Ù… Ù…ØªØ¹Ø¯Ø¯ Ù„Ù†Ù…Ø§Ø°Ø¬ LLM

Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 2.0.0 (AI-Powered)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import os
import json
from typing import Optional, Dict, Any, Literal
from dataclasses import dataclass, asdict
from datetime import datetime
import re

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø§Øª LLM
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False


@dataclass
class AIQueryAnalysis:
    """Ù†ØªÙŠØ¬Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨ÙˆØ§Ø³Ø·Ø© AI"""

    # Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ØµÙ„ÙŠ
    original_query: str

    # Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©
    language: Literal["arabic", "english", "mixed"]

    # Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„
    query_type: Literal[
        "factual",        # Ø³Ø¤Ø§Ù„ Ø­Ù‚ÙŠÙ‚ÙŠ
        "definition",     # ØªØ¹Ø±ÙŠÙ
        "explanation",    # Ø´Ø±Ø­
        "comparison",     # Ù…Ù‚Ø§Ø±Ù†Ø©
        "opinion",        # Ø±Ø£ÙŠ
        "list",           # Ù‚Ø§Ø¦Ù…Ø©
        "procedural"      # Ø¥Ø¬Ø±Ø§Ø¦ÙŠ
    ]

    # Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
    keywords: list[str]

    # Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    main_topic: str

    # Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„ÙØ±Ø¹ÙŠØ©
    sub_topics: list[str]

    # Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙØµÙŠÙ„
    detail_level: Literal["brief", "moderate", "detailed"]

    # Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
    complexity: Literal["simple", "moderate", "complex"]

    # Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© (Ù…Ù† AI)
    search_strategy: Dict[str, Any]

    # ØªÙØ³ÙŠØ± AI Ù„Ù„Ø³Ø¤Ø§Ù„
    ai_interpretation: str

    # Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„
    confidence: float

    # Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    model_used: str

    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    metadata: Dict[str, Any]

    # ÙˆÙ‚Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„
    timestamp: str


class AIQueryAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø£Ø³Ø¦Ù„Ø© Ø°ÙƒÙŠ Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ù€ LLMs"""

    def __init__(
        self,
        provider: Literal["openai", "gemini", "claude", "auto"] = "auto",
        model: Optional[str] = None,
        api_key: Optional[str] = None,
        fallback_to_rules: bool = True
    ):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ù„Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ

        Args:
            provider: Ù…Ø²ÙˆØ¯ Ø§Ù„Ø®Ø¯Ù…Ø© (openai/gemini/claude/auto)
            model: Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø§Ø®ØªÙŠØ§Ø±ÙŠØŒ Ø³ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ)
            api_key: Ù…ÙØªØ§Ø­ API (Ø§Ø®ØªÙŠØ§Ø±ÙŠØŒ Ø³ÙŠØ³ØªØ®Ø¯Ù… Ù…Ù† Ø§Ù„Ø¨ÙŠØ¦Ø©)
            fallback_to_rules: Ø§Ù„Ø±Ø¬ÙˆØ¹ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„
        """
        self.provider = provider
        self.model = model
        self.api_key = api_key
        self.fallback_to_rules = fallback_to_rules

        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø²ÙˆØ¯ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
        self._initialize_provider()

        # Prompt template Ù„Ù„ØªØ­Ù„ÙŠÙ„
        self.analysis_prompt = self._create_analysis_prompt()

    def _initialize_provider(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø²ÙˆØ¯ LLM"""

        if self.provider == "auto":
            # Ø§Ø®ØªÙŠØ§Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØ§Ø­
            if OPENAI_AVAILABLE and os.getenv("OPENAI_API_KEY"):
                self.provider = "openai"
            elif GEMINI_AVAILABLE and os.getenv("GEMINI_API_KEY"):
                self.provider = "gemini"
            elif ANTHROPIC_AVAILABLE and os.getenv("ANTHROPIC_API_KEY"):
                self.provider = "claude"
            else:
                print("âš ï¸  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ API key Ù„Ø£ÙŠ Ù…Ø²ÙˆØ¯ LLM")
                print("   Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯")
                self.provider = "rules"
                return

        # ØªÙ‡ÙŠØ¦Ø© OpenAI
        if self.provider == "openai":
            if not OPENAI_AVAILABLE:
                raise ImportError("OpenAI library not installed. Run: pip install openai")

            api_key = self.api_key or os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OPENAI_API_KEY not found in environment")

            openai.api_key = api_key
            self.model = self.model or "gpt-4-turbo-preview"
            print(f"âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© OpenAI ({self.model})")

        # ØªÙ‡ÙŠØ¦Ø© Gemini
        elif self.provider == "gemini":
            if not GEMINI_AVAILABLE:
                raise ImportError("Google AI library not installed. Run: pip install google-generativeai")

            api_key = self.api_key or os.getenv("GEMINI_API_KEY")
            if not api_key:
                raise ValueError("GEMINI_API_KEY not found in environment")

            genai.configure(api_key=api_key)
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯ gemini-1.5-flash-latest (Ù…Ø¬Ø§Ù†ÙŠ ÙˆØ³Ø±ÙŠØ¹)
            self.model = self.model or "gemini-1.5-flash-latest"
            self.gemini_model = genai.GenerativeModel(self.model)
            print(f"âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Google Gemini ({self.model})")

        # ØªÙ‡ÙŠØ¦Ø© Claude
        elif self.provider == "claude":
            if not ANTHROPIC_AVAILABLE:
                raise ImportError("Anthropic library not installed. Run: pip install anthropic")

            api_key = self.api_key or os.getenv("ANTHROPIC_API_KEY")
            if not api_key:
                raise ValueError("ANTHROPIC_API_KEY not found in environment")

            self.claude_client = anthropic.Anthropic(api_key=api_key)
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø­Ø¯Ø« Ù†Ù…ÙˆØ°Ø¬ Claude Sonnet 4.5
            self.model = self.model or "claude-sonnet-4-5-20250929"
            print(f"âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Anthropic Claude ({self.model})")

    def _create_analysis_prompt(self) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ prompt Ù„Ù„ØªØ­Ù„ÙŠÙ„"""
        return """Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø£Ø³Ø¦Ù„Ø© Ø®Ø¨ÙŠØ± Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¯ÙŠÙ†ÙŠØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©.

Ù…Ù‡Ù…ØªÙƒ: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØªÙ‚Ø¯ÙŠÙ… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ø¹Ù†Ù‡.

Ø§Ù„Ø³Ø¤Ø§Ù„: {query}

Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ£Ø¹Ø·Ù†ÙŠ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨ØµÙŠØºØ© JSON Ø§Ù„ØªØ§Ù„ÙŠØ©:

{{
    "language": "arabic Ø£Ùˆ english Ø£Ùˆ mixed",
    "query_type": "factual Ø£Ùˆ definition Ø£Ùˆ explanation Ø£Ùˆ comparison Ø£Ùˆ opinion Ø£Ùˆ list Ø£Ùˆ procedural",
    "keywords": ["ÙƒÙ„Ù…Ø©1", "ÙƒÙ„Ù…Ø©2", ...],
    "main_topic": "Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ø³Ø¤Ø§Ù„",
    "sub_topics": ["Ù…ÙˆØ¶ÙˆØ¹ ÙØ±Ø¹ÙŠ 1", "Ù…ÙˆØ¶ÙˆØ¹ ÙØ±Ø¹ÙŠ 2", ...],
    "detail_level": "brief Ø£Ùˆ moderate Ø£Ùˆ detailed",
    "complexity": "simple Ø£Ùˆ moderate Ø£Ùˆ complex",
    "ai_interpretation": "ØªÙØ³ÙŠØ±Ùƒ Ù„Ù„Ø³Ø¤Ø§Ù„ ÙˆÙ…Ø§ ÙŠØ¨Ø­Ø« Ø¹Ù†Ù‡ Ø§Ù„Ø³Ø§Ø¦Ù„",
    "confidence": 0.95,
    "search_strategy": {{
        "n_results": 5,
        "level_priority": ["paragraph", "section", "document"],
        "search_focus": "ÙˆØµÙ Ù…Ø§ ÙŠØ¬Ø¨ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„ÙŠÙ‡ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«",
        "suggested_filters": ["ÙÙ„ØªØ±1", "ÙÙ„ØªØ±2", ...]
    }}
}}

Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©:
1. Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠØ© ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø«Ù„: Ù…Ù†ØŒ Ù…Ø§Ø°Ø§ØŒ Ù…Ø§)
2. query_type ÙŠØ­Ø¯Ø¯ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø¯Ù‚Ø©
3. detail_level ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ ÙˆØ¬ÙˆØ¯ ÙƒÙ„Ù…Ø§Øª Ù…Ø«Ù„ "Ø¨Ø§Ù„ØªÙØµÙŠÙ„" Ø£Ùˆ "Ø¨Ø§Ø®ØªØµØ§Ø±"
4. search_strategy ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø°ÙƒÙŠØ§Ù‹ ÙˆÙŠÙ†Ø§Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„
5. confidence Ù‡Ùˆ Ù…Ø¯Ù‰ Ø«Ù‚ØªÙƒ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ (0-1)

Ø£Ø¹Ø·Ù†ÙŠ ÙÙ‚Ø· JSON Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù†Øµ Ø¥Ø¶Ø§ÙÙŠ."""

    def analyze(self, query: str) -> AIQueryAnalysis:
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI

        Args:
            query: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡

        Returns:
            AIQueryAnalysis: Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
        """
        print(f"ğŸ¤– ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI ({self.provider})...")

        try:
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ LLM Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
            if self.provider == "openai":
                result = self._analyze_with_openai(query)
            elif self.provider == "gemini":
                result = self._analyze_with_gemini(query)
            elif self.provider == "claude":
                result = self._analyze_with_claude(query)
            else:
                if self.fallback_to_rules:
                    print("âš ï¸  Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯...")
                    return self._analyze_with_rules(query)
                else:
                    raise ValueError(f"Provider ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: {self.provider}")

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©
            analysis_data = self._parse_llm_response(result, query)

            # Ø¥Ù†Ø´Ø§Ø¡ AIQueryAnalysis
            return AIQueryAnalysis(
                original_query=query,
                language=analysis_data['language'],
                query_type=analysis_data['query_type'],
                keywords=analysis_data['keywords'],
                main_topic=analysis_data['main_topic'],
                sub_topics=analysis_data['sub_topics'],
                detail_level=analysis_data['detail_level'],
                complexity=analysis_data['complexity'],
                search_strategy=analysis_data['search_strategy'],
                ai_interpretation=analysis_data['ai_interpretation'],
                confidence=analysis_data['confidence'],
                model_used=f"{self.provider}/{self.model}",
                metadata={
                    'query_length': len(query),
                    'word_count': len(query.split()),
                    'has_question_mark': '?' in query or 'ØŸ' in query
                },
                timestamp=datetime.now().isoformat()
            )

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}")

            if self.fallback_to_rules:
                print("âš ï¸  Ø§Ù„Ø±Ø¬ÙˆØ¹ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯...")
                return self._analyze_with_rules(query)
            else:
                raise

    def _analyze_with_openai(self, query: str) -> str:
        """ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI"""
        prompt = self.analysis_prompt.format(query=query)

        response = openai.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø£Ø³Ø¦Ù„Ø© Ø®Ø¨ÙŠØ±. Ø£Ø¬Ø¨ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø¨ØµÙŠØºØ© JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )

        return response.choices[0].message.content

    def _analyze_with_gemini(self, query: str) -> str:
        """ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini"""
        prompt = self.analysis_prompt.format(query=query)

        response = self.gemini_model.generate_content(
            prompt,
            generation_config={
                'temperature': 0.3
            }
        )

        return response.text

    def _analyze_with_claude(self, query: str) -> str:
        """ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Claude"""
        prompt = self.analysis_prompt.format(query=query)

        response = self.claude_client.messages.create(
            model=self.model,
            max_tokens=1024,
            temperature=0.3,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )

        return response.content[0].text

    def _parse_llm_response(self, response: str, query: str) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªØ¬Ø§Ø¨Ø© LLM"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
            # Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ Ù†Øµ Ø¥Ø¶Ø§ÙÙŠ Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯ JSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                response = json_match.group()

            data = json.loads(response)

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            required_fields = [
                'language', 'query_type', 'keywords', 'main_topic',
                'sub_topics', 'detail_level', 'complexity',
                'ai_interpretation', 'confidence', 'search_strategy'
            ]

            for field in required_fields:
                if field not in data:
                    raise ValueError(f"Ø­Ù‚Ù„ Ù…ÙÙ‚ÙˆØ¯: {field}")

            return data

        except Exception as e:
            print(f"âš ï¸  Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªØ¬Ø§Ø¨Ø© LLM: {str(e)}")
            # fallback Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯
            raise

    def _analyze_with_rules(self, query: str) -> AIQueryAnalysis:
        """
        ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ (fallback)
        Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ù…Ù† Query Analyzer
        """
        from step4_query_analyzer import QueryAnalyzer

        old_analyzer = QueryAnalyzer()
        old_analysis = old_analyzer.analyze(query)

        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ AIQueryAnalysis
        return AIQueryAnalysis(
            original_query=query,
            language=old_analysis.language,
            query_type=old_analysis.query_type,
            keywords=old_analysis.keywords,
            main_topic=old_analysis.keywords[0] if old_analysis.keywords else "unknown",
            sub_topics=old_analysis.keywords[1:3] if len(old_analysis.keywords) > 1 else [],
            detail_level=old_analysis.detail_level,
            complexity="moderate",  # Ø§ÙØªØ±Ø§Ø¶ÙŠ
            search_strategy=old_analysis.search_strategy,
            ai_interpretation="ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯",
            confidence=old_analysis.query_type_confidence,
            model_used="rules-based",
            metadata=old_analysis.metadata,
            timestamp=old_analysis.timestamp
        )

    def print_analysis(self, analysis: AIQueryAnalysis, verbose: bool = True):
        """Ø·Ø¨Ø§Ø¹Ø© Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø³Ù‚"""

        print("\n" + "="*70)
        print("ğŸ¤– ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
        print("="*70)

        print(f"\nğŸ“ Ø§Ù„Ø³Ø¤Ø§Ù„: {analysis.original_query}")
        print(f"ğŸ¤– Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {analysis.model_used}")
        print(f"ğŸ“Š Ø§Ù„Ø«Ù‚Ø©: {analysis.confidence:.0%}")

        print(f"\nğŸŒ Ø§Ù„Ù„ØºØ©: {analysis.language}")
        print(f"ğŸ“‹ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„: {analysis.query_type}")
        print(f"ğŸ“ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙØµÙŠÙ„: {analysis.detail_level}")
        print(f"ğŸ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯: {analysis.complexity}")

        print(f"\nğŸ’¡ ØªÙØ³ÙŠØ± AI:")
        print(f"   {analysis.ai_interpretation}")

        print(f"\nğŸ¯ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: {analysis.main_topic}")

        if analysis.sub_topics:
            print(f"\nğŸ“Œ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„ÙØ±Ø¹ÙŠØ©:")
            for i, topic in enumerate(analysis.sub_topics, 1):
                print(f"   {i}. {topic}")

        if analysis.keywords:
            print(f"\nğŸ”‘ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©:")
            for i, kw in enumerate(analysis.keywords, 1):
                print(f"   {i}. {kw}")

        print(f"\nğŸ¯ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¨Ø­Ø«:")
        strategy = analysis.search_strategy
        print(f"   â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {strategy.get('n_results', 5)}")
        print(f"   â€¢ Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª: {' â†’ '.join(strategy.get('level_priority', []))}")
        if 'search_focus' in strategy:
            print(f"   â€¢ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰: {strategy['search_focus']}")
        if 'suggested_filters' in strategy and strategy['suggested_filters']:
            print(f"   â€¢ ÙÙ„Ø§ØªØ± Ù…Ù‚ØªØ±Ø­Ø©: {', '.join(strategy['suggested_filters'])}")

        if verbose:
            print(f"\nğŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©:")
            for key, value in analysis.metadata.items():
                print(f"   â€¢ {key}: {value}")

        print("\n" + "="*70 + "\n")


def main():
    """ØªØ¬Ø±Ø¨Ø© AI Query Analyzer"""

    print("\n" + "="*70)
    print("ğŸ¤– Step 4 AI: Query Analyzer Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
    print("="*70 + "\n")

    # Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
    test_queries = [
        "Ù…Ù† Ù‡Ùˆ Ø§Ù„Ø´Ø±ÙŠÙ Ø§Ù„Ù…Ø±ØªØ¶Ù‰ØŸ",
        "Ù…Ø§ Ù‡Ùˆ ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø¥Ù…Ø§Ù…Ø© ÙÙŠ Ø§Ù„ÙÙƒØ± Ø§Ù„Ø´ÙŠØ¹ÙŠØŸ",
        "Ø§Ø´Ø±Ø­ Ø¨Ø§Ù„ØªÙØµÙŠÙ„ Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ø¹ØµÙ…Ø© ÙˆØ£Ø¯Ù„ØªÙ‡",
        "Ù…Ø§ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø¥Ù…Ø§Ù…Ø© ÙˆØ§Ù„Ø®Ù„Ø§ÙØ©ØŸ",
    ]

    # ØªØ¬Ø±Ø¨Ø© Ù…Ø¹ auto (Ø³ÙŠØ®ØªØ§Ø± Ø§Ù„Ù…ØªØ§Ø­)
    try:
        analyzer = AIQueryAnalyzer(provider="auto", fallback_to_rules=True)

        for i, query in enumerate(test_queries, 1):
            print(f"\n{'â”'*70}")
            print(f"Ù…Ø«Ø§Ù„ {i}/{len(test_queries)}")
            print(f"{'â”'*70}\n")

            analysis = analyzer.analyze(query)
            analyzer.print_analysis(analysis)

            if i < len(test_queries):
                input("\nØ§Ø¶ØºØ· Enter Ù„Ù„Ù…Ø«Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ...")

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£: {str(e)}")
        print("\nğŸ’¡ ØªØ£ÙƒØ¯ Ù…Ù†:")
        print("   1. ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª: pip install openai google-generativeai anthropic")
        print("   2. ØªØ¹ÙŠÙŠÙ† API key ÙÙŠ Ø§Ù„Ø¨ÙŠØ¦Ø©:")
        print("      export OPENAI_API_KEY='your-key'")
        print("      export GEMINI_API_KEY='your-key'")
        print("      export ANTHROPIC_API_KEY='your-key'")


if __name__ == "__main__":
    main()
