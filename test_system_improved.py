"""
ğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ù†Ø¸Ø§Ù… RAG - Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù‘Ù†Ø©
================================
"""

from sentence_transformers import SentenceTransformer
import chromadb

def main():
    try:
        # 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        print("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
        model = SentenceTransformer('intfloat/multilingual-e5-large')
        print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")

        # 2. Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        print("\nğŸ”„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        client = chromadb.PersistentClient(path="data/database/chroma_db")

        # Ø¹Ø±Ø¶ Collections Ø§Ù„Ù…ØªØ§Ø­Ø©
        collections = client.list_collections()
        print(f"âœ… Ø¹Ø¯Ø¯ Collections Ø§Ù„Ù…ØªØ§Ø­Ø©: {len(collections)}")

        for col in collections:
            print(f"   - {col.name} ({col.count()} Ø¹Ù†ØµØ±)")

        # Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Collection
        collection_name = "islamic_books_e5"
        collection = client.get_collection(collection_name)
        print(f"âœ… ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Collection: {collection_name}")

        # 3. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø«
        test_queries = [
            "Ù…Ù† Ù‡Ùˆ Ø§Ù„Ø´Ø±ÙŠÙ Ø§Ù„Ù…Ø±ØªØ¶Ù‰ØŸ",
            "Ù…Ø§ Ù‡Ùˆ Ù…ÙˆØ¶ÙˆØ¹ ÙƒØªØ§Ø¨ Ø§Ù„Ø´Ø§ÙÙŠ ÙÙŠ Ø§Ù„Ø¥Ù…Ø§Ù…Ø©ØŸ",
            "Ø§Ø´Ø±Ø­ Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ø¥Ù…Ø§Ù…Ø©"
        ]

        for query in test_queries:
            print(f"\n{'='*60}")
            print(f"ğŸ” Ø§Ù„Ø³Ø¤Ø§Ù„: {query}")
            print(f"{'='*60}\n")

            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„Ù€ vector (Ù…Ø¹ Ø¨Ø§Ø¯Ø¦Ø© query: Ø­Ø³Ø¨ Ù…ØªØ·Ù„Ø¨Ø§Øª E5)
            query_embedding = model.encode(f"query: {query}")

            # Ø§Ù„Ø¨Ø­Ø«
            results = collection.query(
                query_embeddings=[query_embedding.tolist()],
                n_results=3  # Ø£ÙØ¶Ù„ 3 Ù†ØªØ§Ø¦Ø¬ ÙÙ‚Ø·
            )

            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            if results['ids'][0]:
                print("ğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:\n")
                for i, (id, metadata, doc, distance) in enumerate(zip(
                    results['ids'][0],
                    results['metadatas'][0],
                    results['documents'][0],
                    results['distances'][0]
                ), 1):
                    print(f"{i}. [{metadata['type']}] {id}")
                    print(f"   ğŸ“Š Distance: {distance:.4f}")
                    if 'title' in metadata:
                        print(f"   ğŸ“– Ø§Ù„ÙƒØªØ§Ø¨: {metadata['title']}")
                    print(f"   ğŸ“ {doc[:150]}...")
                    print()
            else:
                print("âš ï¸  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬")

        print(f"\n{'='*60}")
        print("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­!")
        print(f"{'='*60}")

    except chromadb.errors.NotFoundError as e:
        print(f"\nâŒ Ø®Ø·Ø£: Collection ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        print(f"   {str(e)}")
        print("\nğŸ’¡ Ø§Ù„Ø­Ù„:")
        print("   1. ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ step3_embeddings_E5.py Ø£ÙˆÙ„Ø§Ù‹")
        print("   2. Ø£Ùˆ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø³Ù… Collection ÙÙŠ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª")

    except ImportError as e:
        print(f"\nâŒ Ø®Ø·Ø£: Ù…ÙƒØªØ¨Ø© ØºÙŠØ± Ù…Ø«Ø¨ØªØ©")
        print(f"   {str(e)}")
        print("\nğŸ’¡ Ø§Ù„Ø­Ù„:")
        print("   pip install -r requirements.txt")

    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹:")
        print(f"   {type(e).__name__}: {str(e)}")

if __name__ == "__main__":
    main()
